# Design: 修复 AI 标签功能集成

## Context

AI 标签功能的基础代码已经实现，但实际运行时无法正常工作。模型文件（`swin-v2-tagger-v3.onnx` 和 `selected_tags.csv`）已经下载到 `src-tauri/models/` 目录。需要系统性地测试和修复整个流程。

## Goals / Non-Goals

### Goals
- 验证模型文件能够正确加载
- 验证模型推理能够正常工作并返回有效标签
- 修复模型路径解析，确保开发和生产环境都能找到模型
- 确保导入流程中 AI 标签能够正常触发和执行
- 改进错误处理和日志，便于问题诊断

### Non-Goals
- 不改变现有的 AI 标签架构设计
- 不优化模型推理性能（除非发现明显问题）
- 不改变前端 UI 设计（只修复功能）

## Decisions

### Decision: 分阶段实现 - 先测试模型，再集成前端

**Rationale**: 
- 模型测试是基础，必须先确保模型能正常工作
- 前端集成依赖于后端功能正常
- 分阶段可以更快定位问题

**Alternatives considered**:
- 一次性修复所有问题：风险高，难以定位问题根源
- 只修复前端：可能后端问题未解决

### Decision: 添加独立的测试命令

**Rationale**:
- 可以快速验证模型加载和推理是否正常
- 不依赖导入流程，便于独立测试
- 便于后续调试和问题排查

**Alternatives considered**:
- 只通过导入流程测试：难以定位是模型问题还是集成问题
- 使用单元测试：需要准备测试图片，不如直接命令方便

### Decision: 改进模型路径解析逻辑

**Rationale**:
- 当前的 `get_models_dir()` 使用多层 `parent()` 调用，在开发环境中可能不稳定
- 应该使用更可靠的方式（如 `CARGO_MANIFEST_DIR` 环境变量）来定位模型目录

**Alternatives considered**:
- 保持当前实现：可能在某些环境下失败
- 硬编码路径：不够灵活

## Risks / Trade-offs

### Risks
- **模型文件路径问题**: 如果路径解析失败，所有 AI 功能都无法工作
  - **Mitigation**: 添加详细的错误日志，提供明确的路径信息

- **模型加载失败**: ONNX Runtime 初始化可能失败
  - **Mitigation**: 添加详细的错误信息，检查依赖和硬件支持

- **推理性能问题**: 如果推理太慢，可能影响用户体验
  - **Mitigation**: 当前实现已经是异步的，不会阻塞主流程

### Trade-offs
- **测试命令 vs 单元测试**: 选择测试命令是为了快速验证，但单元测试更自动化
  - **选择**: 测试命令，因为更灵活，可以测试真实场景

## Implementation Plan

### Phase 1: 模型测试
1. 创建测试命令 `test_ai_model(image_path)` 
2. 验证模型文件能够加载
3. 验证推理能够返回有效标签
4. 记录推理时间和使用的执行提供者

### Phase 2: 路径修复
1. 改进 `get_models_dir()` 使用 `CARGO_MANIFEST_DIR`
2. 添加详细的错误日志
3. 验证开发和生产环境都能正确找到模型

### Phase 3: 集成验证
1. 验证导入流程中 AI 标签能够触发
2. 验证标签能够正确保存到数据库
3. 验证前端能够收到进度事件

### Phase 4: 前端集成
1. 确保前端能正确显示 AI 标签进度
2. 确保标签能够正确显示在 UI 中
3. 测试手动触发 AI 标签功能

## Open Questions

- 模型文件在生产环境中应该如何部署？（当前设计是放在可执行文件同目录）
- 是否需要添加模型文件完整性校验？

